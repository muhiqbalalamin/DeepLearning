{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1afxMRCja_iZgV9pSGVcg16JpvVcslNvj",
      "authorship_tag": "ABX9TyNRb7C98XwPEhtpraz96Px/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhiqbalalamin/DeepLearning/blob/main/Regression_Infrared_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCk7hu81F5Rn",
        "outputId": "7be08a3d-00d1-4a82-e206-1f5c394ed25d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbdIQ3HuFQMf",
        "outputId": "f1d89273-de32-4067-f38c-0531f80a7950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip-8yRYYHHBs",
        "outputId": "43063183-0807-4baa-a9d4-6d69a3638586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "data_path = '/content/drive/MyDrive/Folder DL/Infrared.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Handle missing values\n",
        "df = df.dropna(subset=['Distance'])\n",
        "\n",
        "# One-hot encoding for categorical features\n",
        "df = pd.get_dummies(df, columns=['Gender', 'Age', 'Ethnicity'], drop_first=True)\n",
        "\n",
        "# Split features and target\n",
        "X = df.drop(columns=['aveOralM'])\n",
        "y = df['aveOralM'].values.reshape(-1, 1)\n",
        "\n",
        "# Standardize numerical features\n",
        "scaler_X = StandardScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "\n",
        "# Normalize target variable\n",
        "y_scaler = StandardScaler()\n",
        "y_scaled = y_scaler.fit_transform(y)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X_train, X_test = np.array(X_train), np.array(X_test)\n",
        "y_train, y_test = np.array(y_train), np.array(y_test)\n",
        "\n",
        "# PyTorch Model\n",
        "class DeepModelTorch(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(DeepModelTorch, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),   # W*x + b\n",
        "            nn.ReLU(),                  # max(0, x)\n",
        "            nn.BatchNorm1d(64),         # (x - batch_mean) / (batch_std + epsilon)\n",
        "            nn.Dropout(0.2),            # Each neuron has 0.2 probability of being zeroed\n",
        "            nn.Linear(64, 32),          # W*x + b\n",
        "            nn.ReLU(),                  # max(0, x)\n",
        "            nn.Linear(32, 1)            # Final output layer\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Initialize PyTorch model\n",
        "input_dim = X_train.shape[1]\n",
        "model_torch = DeepModelTorch(input_dim)\n",
        "criterion = nn.MSELoss()  # Implements MSE equation\n",
        "optimizer = optim.Adam(model_torch.parameters(), lr=0.0001)\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train_torch = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_torch = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_test_torch = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_torch = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# Training history tracking\n",
        "torch_losses = []\n",
        "\n",
        "# Train PyTorch model\n",
        "for epoch in range(100):\n",
        "    model_torch.train()  # Set model to training mode\n",
        "    optimizer.zero_grad()  # Reset gradients\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model_torch(X_train_torch)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = criterion(outputs, y_train_torch)\n",
        "\n",
        "    # Backward pass (computes ∇θJ(θ))\n",
        "    loss.backward()\n",
        "\n",
        "    # Update weights (θ = θ - α * ∇θJ(θ))\n",
        "    optimizer.step()\n",
        "\n",
        "    torch_losses.append(loss.item())\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
        "\n",
        "print(\"PyTorch model training complete!\")\n",
        "\n",
        "# Predict with PyTorch model\n",
        "model_torch.eval()  # Set model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    y_pred_torch = model_torch(X_test_torch).numpy()\n",
        "\n",
        "    # Inverse transform to get original scale\n",
        "    y_test_original = y_scaler.inverse_transform(y_test)\n",
        "    y_pred_torch_original = y_scaler.inverse_transform(y_pred_torch)\n",
        "\n",
        "# TensorFlow Model\n",
        "model_tf = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile TensorFlow model\n",
        "model_tf.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='mse', metrics=['mse'])\n",
        "\n",
        "# Train TensorFlow model\n",
        "history = model_tf.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    verbose=1,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1\n",
        ")\n",
        "\n",
        "# Predict with TensorFlow model\n",
        "y_pred_tf = model_tf.predict(X_test)\n",
        "y_pred_tf_original = y_scaler.inverse_transform(y_pred_tf)\n",
        "\n",
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    y_true = y_true.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "\n",
        "    # Mean Squared Error\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "\n",
        "    # Root Mean Squared Error\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    # R-squared (coefficient of determination)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "    print(f\"{model_name} Evaluation:\")\n",
        "    print(f\"MSE: {mse:.4f}\")\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "    print(f\"R-Squared: {r2:.4f}\\n\")\n",
        "\n",
        "    return mse, rmse, r2\n",
        "\n",
        "# Evaluate both models\n",
        "torch_metrics = evaluate_model(y_test_original, y_pred_torch_original, \"PyTorch Model\")\n",
        "tf_metrics = evaluate_model(y_test_original, y_pred_tf_original, \"TensorFlow Model\")\n"
      ],
      "metadata": {
        "id": "kgEj1WZGcmlu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8825773-64a3-4bc2-f60f-811fd06a176e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 1.2308884859085083\n",
            "Epoch 10, Loss: 1.1031980514526367\n",
            "Epoch 20, Loss: 0.9842941164970398\n",
            "Epoch 30, Loss: 0.885841965675354\n",
            "Epoch 40, Loss: 0.7898789644241333\n",
            "Epoch 50, Loss: 0.6847495436668396\n",
            "Epoch 60, Loss: 0.6239565014839172\n",
            "Epoch 70, Loss: 0.5339627861976624\n",
            "Epoch 80, Loss: 0.5031497478485107\n",
            "Epoch 90, Loss: 0.46035173535346985\n",
            "PyTorch model training complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 2.1855 - mse: 2.1855 - val_loss: 1.0993 - val_mse: 1.0993\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8382 - mse: 1.8382 - val_loss: 0.9059 - val_mse: 0.9059\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5370 - mse: 1.5370 - val_loss: 0.7870 - val_mse: 0.7870\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4590 - mse: 1.4590 - val_loss: 0.7012 - val_mse: 0.7012\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2181 - mse: 1.2181 - val_loss: 0.6489 - val_mse: 0.6489\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0788 - mse: 1.0788 - val_loss: 0.6086 - val_mse: 0.6086\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9363 - mse: 0.9363 - val_loss: 0.5874 - val_mse: 0.5874\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9195 - mse: 0.9195 - val_loss: 0.5559 - val_mse: 0.5559\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9975 - mse: 0.9975 - val_loss: 0.5467 - val_mse: 0.5467\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8086 - mse: 0.8086 - val_loss: 0.5317 - val_mse: 0.5317\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9120 - mse: 0.9120 - val_loss: 0.5198 - val_mse: 0.5198\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7938 - mse: 0.7938 - val_loss: 0.5179 - val_mse: 0.5179\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6993 - mse: 0.6993 - val_loss: 0.5034 - val_mse: 0.5034\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7362 - mse: 0.7362 - val_loss: 0.5045 - val_mse: 0.5045\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7157 - mse: 0.7157 - val_loss: 0.5053 - val_mse: 0.5053\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6562 - mse: 0.6562 - val_loss: 0.4834 - val_mse: 0.4834\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6997 - mse: 0.6997 - val_loss: 0.4725 - val_mse: 0.4725\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7795 - mse: 0.7795 - val_loss: 0.4598 - val_mse: 0.4598\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5625 - mse: 0.5625 - val_loss: 0.4509 - val_mse: 0.4509\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6037 - mse: 0.6037 - val_loss: 0.4469 - val_mse: 0.4469\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5770 - mse: 0.5770 - val_loss: 0.4424 - val_mse: 0.4424\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6134 - mse: 0.6134 - val_loss: 0.4248 - val_mse: 0.4248\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5901 - mse: 0.5901 - val_loss: 0.4205 - val_mse: 0.4205\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5232 - mse: 0.5232 - val_loss: 0.4147 - val_mse: 0.4147\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5461 - mse: 0.5461 - val_loss: 0.4142 - val_mse: 0.4142\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5143 - mse: 0.5143 - val_loss: 0.4115 - val_mse: 0.4115\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5418 - mse: 0.5418 - val_loss: 0.4104 - val_mse: 0.4104\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5897 - mse: 0.5897 - val_loss: 0.3988 - val_mse: 0.3988\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4188 - mse: 0.4188 - val_loss: 0.3904 - val_mse: 0.3904\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5820 - mse: 0.5820 - val_loss: 0.3825 - val_mse: 0.3825\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4939 - mse: 0.4939 - val_loss: 0.3747 - val_mse: 0.3747\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4862 - mse: 0.4862 - val_loss: 0.3715 - val_mse: 0.3715\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4090 - mse: 0.4090 - val_loss: 0.3739 - val_mse: 0.3739\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5590 - mse: 0.5590 - val_loss: 0.3774 - val_mse: 0.3774\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.4826 - mse: 0.4826 - val_loss: 0.3751 - val_mse: 0.3751\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.5367 - mse: 0.5367 - val_loss: 0.3758 - val_mse: 0.3758\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.4443 - mse: 0.4443 - val_loss: 0.3711 - val_mse: 0.3711\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5439 - mse: 0.5439 - val_loss: 0.3683 - val_mse: 0.3683\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4942 - mse: 0.4942 - val_loss: 0.3639 - val_mse: 0.3639\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4053 - mse: 0.4053 - val_loss: 0.3626 - val_mse: 0.3626\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.5572 - mse: 0.5572 - val_loss: 0.3516 - val_mse: 0.3516\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5226 - mse: 0.5226 - val_loss: 0.3516 - val_mse: 0.3516\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4242 - mse: 0.4242 - val_loss: 0.3484 - val_mse: 0.3484\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4733 - mse: 0.4733 - val_loss: 0.3394 - val_mse: 0.3394\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4338 - mse: 0.4338 - val_loss: 0.3360 - val_mse: 0.3360\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4871 - mse: 0.4871 - val_loss: 0.3317 - val_mse: 0.3317\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4395 - mse: 0.4395 - val_loss: 0.3351 - val_mse: 0.3351\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3690 - mse: 0.3690 - val_loss: 0.3339 - val_mse: 0.3339\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4613 - mse: 0.4613 - val_loss: 0.3335 - val_mse: 0.3335\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4406 - mse: 0.4406 - val_loss: 0.3351 - val_mse: 0.3351\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4090 - mse: 0.4090 - val_loss: 0.3310 - val_mse: 0.3310\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4093 - mse: 0.4093 - val_loss: 0.3288 - val_mse: 0.3288\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4116 - mse: 0.4116 - val_loss: 0.3209 - val_mse: 0.3209\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4113 - mse: 0.4113 - val_loss: 0.3207 - val_mse: 0.3207\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4172 - mse: 0.4172 - val_loss: 0.3230 - val_mse: 0.3230\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4033 - mse: 0.4033 - val_loss: 0.3195 - val_mse: 0.3195\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3868 - mse: 0.3868 - val_loss: 0.3164 - val_mse: 0.3164\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4239 - mse: 0.4239 - val_loss: 0.3086 - val_mse: 0.3086\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4375 - mse: 0.4375 - val_loss: 0.3106 - val_mse: 0.3106\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4427 - mse: 0.4427 - val_loss: 0.3124 - val_mse: 0.3124\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3919 - mse: 0.3919 - val_loss: 0.3134 - val_mse: 0.3134\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4408 - mse: 0.4408 - val_loss: 0.3157 - val_mse: 0.3157\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3800 - mse: 0.3800 - val_loss: 0.3145 - val_mse: 0.3145\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3500 - mse: 0.3500 - val_loss: 0.3126 - val_mse: 0.3126\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5024 - mse: 0.5024 - val_loss: 0.3134 - val_mse: 0.3134\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4099 - mse: 0.4099 - val_loss: 0.3074 - val_mse: 0.3074\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4026 - mse: 0.4026 - val_loss: 0.3089 - val_mse: 0.3089\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3929 - mse: 0.3929 - val_loss: 0.3117 - val_mse: 0.3117\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3769 - mse: 0.3769 - val_loss: 0.3130 - val_mse: 0.3130\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3489 - mse: 0.3489 - val_loss: 0.3128 - val_mse: 0.3128\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4625 - mse: 0.4625 - val_loss: 0.3121 - val_mse: 0.3121\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3533 - mse: 0.3533 - val_loss: 0.3127 - val_mse: 0.3127\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4053 - mse: 0.4053 - val_loss: 0.3115 - val_mse: 0.3115\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3744 - mse: 0.3744 - val_loss: 0.3089 - val_mse: 0.3089\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3405 - mse: 0.3405 - val_loss: 0.3046 - val_mse: 0.3046\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3593 - mse: 0.3593 - val_loss: 0.3055 - val_mse: 0.3055\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4058 - mse: 0.4058 - val_loss: 0.3039 - val_mse: 0.3039\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3576 - mse: 0.3576 - val_loss: 0.3043 - val_mse: 0.3043\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3088 - mse: 0.3088 - val_loss: 0.3070 - val_mse: 0.3070\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3513 - mse: 0.3513 - val_loss: 0.3083 - val_mse: 0.3083\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3443 - mse: 0.3443 - val_loss: 0.3066 - val_mse: 0.3066\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3282 - mse: 0.3282 - val_loss: 0.3067 - val_mse: 0.3067\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3879 - mse: 0.3879 - val_loss: 0.3070 - val_mse: 0.3070\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3408 - mse: 0.3408 - val_loss: 0.3036 - val_mse: 0.3036\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3552 - mse: 0.3552 - val_loss: 0.3055 - val_mse: 0.3055\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3277 - mse: 0.3277 - val_loss: 0.3053 - val_mse: 0.3053\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3143 - mse: 0.3143 - val_loss: 0.3072 - val_mse: 0.3072\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3741 - mse: 0.3741 - val_loss: 0.3024 - val_mse: 0.3024\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3451 - mse: 0.3451 - val_loss: 0.3055 - val_mse: 0.3055\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3188 - mse: 0.3188 - val_loss: 0.3118 - val_mse: 0.3118\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3544 - mse: 0.3544 - val_loss: 0.3083 - val_mse: 0.3083\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3249 - mse: 0.3249 - val_loss: 0.3056 - val_mse: 0.3056\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3481 - mse: 0.3481 - val_loss: 0.3072 - val_mse: 0.3072\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3666 - mse: 0.3666 - val_loss: 0.3084 - val_mse: 0.3084\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3568 - mse: 0.3568 - val_loss: 0.3079 - val_mse: 0.3079\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3342 - mse: 0.3342 - val_loss: 0.3088 - val_mse: 0.3088\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3157 - mse: 0.3157 - val_loss: 0.3080 - val_mse: 0.3080\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3802 - mse: 0.3802 - val_loss: 0.3060 - val_mse: 0.3060\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2900 - mse: 0.2900 - val_loss: 0.3117 - val_mse: 0.3117\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3369 - mse: 0.3369 - val_loss: 0.3095 - val_mse: 0.3095\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "PyTorch Model Evaluation:\n",
            "MSE: 0.0712\n",
            "RMSE: 0.2668\n",
            "R-Squared: 0.6422\n",
            "\n",
            "TensorFlow Model Evaluation:\n",
            "MSE: 0.0770\n",
            "RMSE: 0.2774\n",
            "R-Squared: 0.6130\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Penjelasan metrik evaluasi:\n",
        "## EQUATION 1: Standardization (Z-score normalization)\n",
        "For each feature x:\n",
        "\n",
        "    z = (x - μ) / σ\n",
        "where:\n",
        "\n",
        "    z = standardized value\n",
        "    x = original value\n",
        "    μ = mean of the feature\n",
        "    σ = standard deviation of the feature\n",
        "\n",
        "This transforms features to have mean=0 and standard deviation=1\n",
        "\n",
        "## EQUATION 2: Neural Network Forward Pass\n",
        "For each layer l:\n",
        "\n",
        "    z^(l) = W^(l) * a^(l-1) + b^(l)\n",
        "    a^(l) = activation(z^(l))\n",
        "where:\n",
        "\n",
        "    z^(l) = weighted input to layer l\n",
        "    W^(l) = weight matrix for layer l\n",
        "    a^(l-1) = activations from previous layer\n",
        "    b^(l) = bias vector for layer l\n",
        "    activation() = activation function (ReLU for hidden layers)\n",
        "\n",
        "\n",
        "## EQUATION 3: Mean Squared Error Loss\n",
        "\n",
        "    MSE = (1/n) * Σ(y_i - ŷ_i)²\n",
        "where:\n",
        "\n",
        "    n = number of samples\n",
        "    y_i = true value\n",
        "    ŷ_i = predicted value\n",
        "\n",
        "\n",
        "## EQUATION 4: Backpropagation and Gradient Descent\n",
        "\n",
        "    θ = θ - α * ∇θJ(θ)\n",
        "where:\n",
        "\n",
        "    θ = model parameters (weights and biases)\n",
        "    α = learning rate (0.0001 in our case)\n",
        "    ∇θJ(θ) = gradient of the loss function with respect to parameters\n",
        "\n",
        "\n",
        "## EQUATION 5: Batch Normalization\n",
        "\n",
        "    BN(x) = γ * ((x - μ_B) / sqrt(σ²_B + ε)) + β\n",
        "where:\n",
        "\n",
        "    x = input values\n",
        "    μ_B = mini-batch mean\n",
        "    σ²_B = mini-batch variance\n",
        "    γ, β = learnable parameters\n",
        "    ε = small constant for numerical stability\n",
        "\n",
        "\n",
        "## EQUATION 6: Evaluation Metrics\n",
        "\n",
        "MSE (Mean Squared Error):\n",
        "\n",
        "    MSE = (1/n) * Σ(y_i - ŷ_i)²\n",
        "\n",
        "RMSE (Root Mean Squared Error):\n",
        "\n",
        "    RMSE = sqrt(MSE) = sqrt((1/n) * Σ(y_i - ŷ_i)²)\n",
        "\n",
        "R² (Coefficient of Determination):\n",
        "\n",
        "    R² = 1 - (SS_res / SS_tot)\n",
        "    where:\n",
        "        SS_res = Σ(y_i - ŷ_i)² (Sum of squares of residuals)\n",
        "        SS_tot = Σ(y_i - y_mean)² (Total sum of squares)"
      ],
      "metadata": {
        "id": "OzigkhTR9Xt-"
      }
    }
  ]
}